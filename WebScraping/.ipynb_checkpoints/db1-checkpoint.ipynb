{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import psycopg2 as pg2\n",
    "import logging\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "with open('att_url.csv', 'rb') as csvfile:\n",
    "    u = list(csv.reader(csvfile))\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\n",
    "                    datefmt='%a, %d %b %Y %H:%M:%S',\n",
    "                    filename='myapp.log',\n",
    "                    filemode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/Attraction_Review-g186338-d188862-Reviews-National_Gallery-London_England.html'],\n",
       " ['/Attraction_Review-g186338-d187555-Reviews-British_Museum-London_England.html'],\n",
       " ['/Attraction_Review-g186338-d187556-Reviews-V_A_Victoria_and_Albert_Museum-London_England.html']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "page = 0\n",
    "for x in ur:\n",
    "    page = page + 1\n",
    "    try:\n",
    "        page_recq = requests.get('https://www.tripadvisor.com' + x[0], timeout=5)\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        logging.exception(\"Fail to requestion link: %, page: %d\", x[0], page)  \n",
    "    soup = BeautifulSoup(page_recq.content, \"html.parser\")\n",
    "    \n",
    "#=====================================================================================================================\n",
    "# Attraction name\n",
    "#=====================================================================================================================\n",
    "    try:\n",
    "        attraction = soup.find('h1', {'id':'HEADING'}).getText()\n",
    "        logging.info('page %d: %s', page, attraction)\n",
    "    except:\n",
    "        continue\n",
    "#=====================================================================================================================\n",
    "# Popularity ranking\n",
    "#=====================================================================================================================\n",
    "    try:\n",
    "        ranking = soup.find('b', {'class':''}).getText()\n",
    "    except:\n",
    "        ranking = 'missing'\n",
    "#=====================================================================================================================\n",
    "# Rating\n",
    "#=====================================================================================================================\n",
    "    try:\n",
    "        rating = soup.find('span', {'class':'overallRating'}).getText()\n",
    "    except:\n",
    "        rating = 'missing'\n",
    "#=====================================================================================================================\n",
    "# Number of reviews\n",
    "#=====================================================================================================================\n",
    "    try:\n",
    "        nreview = soup.find('a', {'href':'#REVIEWS'}).getText().split()[0]\n",
    "    except:\n",
    "        nreview = 'missing'\n",
    "#=====================================================================================================================\n",
    "# Address\n",
    "#=====================================================================================================================\n",
    "    try:\n",
    "        address = soup.find('div', {'class':'detail_section address'}).getText()\n",
    "    except:\n",
    "        address = 'missing'\n",
    "#=====================================================================================================================\n",
    "# Street\n",
    "#=====================================================================================================================\n",
    "    try:\n",
    "        street = soup.find('span', {'class':'street-address'}).getText()\n",
    "    except:\n",
    "        street = 'missing' \n",
    "#=====================================================================================================================\n",
    "# Locality\n",
    "#=====================================================================================================================\n",
    "    try:\n",
    "        locality = soup.find('span', {'class':'locality'}).getText()\n",
    "    except:\n",
    "        locality = 'missing' \n",
    "#=====================================================================================================================\n",
    "# Category\n",
    "#=====================================================================================================================\n",
    "    try:\n",
    "        cate = soup.find('div', {'class':'detail'}).getText()\n",
    "    except:\n",
    "        cate = 'missing'\n",
    "#=====================================================================================================================\n",
    "# Phone\n",
    "#=====================================================================================================================\n",
    "    try:\n",
    "        ph = soup.find('div', {'class':'detail_section phone'}).getText()\n",
    "    except:\n",
    "        ph = 'missing'\n",
    "#=====================================================================================================================\n",
    "# Visit Duration\n",
    "#=====================================================================================================================\n",
    "    try:\n",
    "        duration = soup.find('div', {'class':'detail_section duration'}).getText()\n",
    "    except:\n",
    "        duration = 'missing'\n",
    "#=====================================================================================================================\n",
    "# Open Hours\n",
    "#=====================================================================================================================\n",
    "    try:\n",
    "        hrs = soup.find('div', {'class':'detail_section hours'}).getText()\n",
    "    except:\n",
    "        hrs = 'missing'\n",
    "#=====================================================================================================================\n",
    "# Neighborhood\n",
    "#=====================================================================================================================\n",
    "    try:\n",
    "        neighborhood = soup.find('div', {'class':'detail_section neighborhood'}).getText()\n",
    "    except:\n",
    "        neighborhood = 'missing'\n",
    "#=====================================================================================================================\n",
    "# Description\n",
    "#=====================================================================================================================\n",
    "    try:\n",
    "        desc = soup.find('div', {'class':'modal-card-body'}).getText()\n",
    "    except:\n",
    "        desc = 'missing'\n",
    "#=====================================================================================================================\n",
    "# Tags\n",
    "#=====================================================================================================================\n",
    "    try:\n",
    "        tags0 = soup.find_all('div', {'class':'tagWord'})\n",
    "        tag = []\n",
    "        for t in tags0:\n",
    "            tag.append(t.getText()[1:-1])\n",
    "        tags = '; '.join(tag)\n",
    "    except:\n",
    "        tags = 'missing'\n",
    "#=====================================================================================================================\n",
    "# Languages\n",
    "#=====================================================================================================================\n",
    "    try:\n",
    "        langs = soup.find('ul', {'class':'langs'})\n",
    "        l0 = langs.find_all('label', {'class':'filterLabel'})\n",
    "        lang = []\n",
    "        for l in l0:\n",
    "            lang.append(l.getText()) \n",
    "        languages = '; '.join(lang)\n",
    "    except:\n",
    "        languages = 'missing'\n",
    "        \n",
    "#=====================================================================================================================\n",
    "# Save to database\n",
    "#=====================================================================================================================\n",
    "    conn = pg2.connect(host=\"localhost\",database=\"suppliers\", user=\"postgres\", password=\"postgres\")\n",
    "    cur = conn.cursor()\n",
    "    sql = \"\"\"INSERT INTO a1(attraction, ranking, rating, review_num, address, street, locality, category, phone, duration, hours, neighborhood, description, tags, languages) VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\"\"\"\n",
    "    cur.execute(sql, (attraction, ranking, rating, nreview, address, street, locality, cate, ph, duration, hrs, neighborhood, desc, tags, languages))\n",
    "    conn.commit()\n",
    "#=====================================================================================================================\n",
    "# Reviews\n",
    "#=====================================================================================================================\n",
    "    r0 = soup.find_all('div', {'class':'reviewSelector'})\n",
    "    for r in r0:\n",
    "\n",
    "        try:\n",
    "            user = r.find('div', {'class':'username mo'}).getText()\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    #     \n",
    "        try:\n",
    "            cu = r.find('div', {'class':'memberBadgingNoText'})\n",
    "            cuv = cu.find_all('span', {'class':'badgetext'})\n",
    "            user_Contributions = cuv[0].getText()\n",
    "        except:\n",
    "            user_Contributions = 0\n",
    "            user_UpVotes = 0\n",
    "        try:\n",
    "            user_UpVotes = cuv[1].getText()\n",
    "        except:\n",
    "            user_UpVotes = 0\n",
    "\n",
    "        try:\n",
    "            user_location = r.find('div', {'class':'location'}).getText()\n",
    "        except:\n",
    "            user_location = 'missing'\n",
    "\n",
    "        try:\n",
    "            review_date = r.find('span', {'class':'ratingDate relativeDate'})['title']\n",
    "        except:\n",
    "            review_date = 'missing'\n",
    "\n",
    "        try:\n",
    "            viamobile = r.find('span', {'class':'viaMobile'}).getText()\n",
    "        except:\n",
    "            viamobile = 'no'\n",
    "\n",
    "        try:\n",
    "            quote = r.find('span', {'class':'noQuotes'}).getText()\n",
    "        except:\n",
    "            quote = 'missing'\n",
    "\n",
    "        try:\n",
    "            review = r.find('p', {'class':'partial_entry'}).getText()\n",
    "        except:\n",
    "            review = 'missing'\n",
    "\n",
    "        sql = \"\"\"INSERT INTO r2(userID, attraction, user_location, user_Contributions, user_UpVotes, viaMobile, review_quote, review_content) VALUES(%s, %s, %s, %s, %s, %s, %s, %s);\"\"\"\n",
    "        cur.execute(sql, (user, attraction, user_location, user_Contributions, user_UpVotes, viamobile, quote, review))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
